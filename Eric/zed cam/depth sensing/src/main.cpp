///////////////////////////////////////////////////////////////////////////
//
// Copyright (c) 2017, STEREOLABS.
//
// All rights reserved.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//
///////////////////////////////////////////////////////////////////////////


/*************************************************************************
 ** This sample demonstrates how to capture images and 3D point cloud   **
 ** with the ZED SDK and display the result in an OpenGL window. 		    **
 *************************************************************************/

 // Standard includes
#include <stdio.h>
#include <string.h>
#include <unistd.h>
#include <stdlib.h>

// ZED includes
#include <sl_zed/Camera.hpp>

// Sample includes
#include "GLViewer.hpp"

// OpenCV includes
#include "opencv2/opencv.hpp"

// TCPIP includes
#include <sys/types.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <netdb.h>

// Using std and sl namespaces
using namespace std;
using namespace sl;

// Create ZED objects (camera, callback, images)
sl::Camera zed;
sl::Mat point_cloud;
std::thread zed_callback;
int width, height;
bool quit;

// Initialize data for background substraction
cv::Mat fgMaskMOG2; // fg mask generated by MOG2 method
cv::Ptr<cv::BackgroundSubtractor> pMOG2;

// Initialize socket parameters
int sockfd, portno, n;
struct sockaddr_in serv_addr;
struct hostent *server;

// Point cloud viewer
GLViewer viewer;

// OpenCV functions and objects
cv::Mat slMat2cvMat(Mat& input);
void printHelp();

// Sample functions
void startZED();
void run();
void close();

// Error message for networking
void error(const char *msg);

// Color conversion
union pColor{
    float a;
    uint8_t b[4];
} color;

int main(int argc, char **argv) {
    // Establish socket and connection
    portno = 8890;
    sockfd = socket(AF_INET, SOCK_STREAM, 0);
    if (sockfd < 0) error("Error opening socket!");
    server = gethostbyname("149.171.37.126");
    //server = gethostbyname("127.0.0.1");
    if (server == NULL) {
        fprintf(stderr, "Error, no such host!\n");
        exit(0);
    }                
    bzero((char *)&serv_addr, sizeof(serv_addr));
    serv_addr.sin_family = AF_INET;
    bcopy((char *)server->h_addr,
        (char *)&serv_addr.sin_addr.s_addr,
        server->h_length);
    serv_addr.sin_port = htons(portno);
    if (connect(sockfd,(struct sockaddr *)&serv_addr,sizeof(serv_addr)) < 0) error("Error connecting!");

    cout << endl;
    cout << "*************************************" << endl;
    cout << "**     Connection established!     **" << endl;
    cout << "*************************************" << endl;
    cout << endl;

    // Create background substrctor objects
    pMOG2=cv::createBackgroundSubtractorMOG2();
                
    // Set configuration parameters for the ZED
    InitParameters initParameters;
    if (argc == 2) initParameters.svo_input_filename = argv[1];
    initParameters.camera_resolution = RESOLUTION_HD720;
    initParameters.depth_mode = DEPTH_MODE_PERFORMANCE;
    initParameters.coordinate_system = COORDINATE_SYSTEM_RIGHT_HANDED_Y_UP; // OpenGL's coordinate system is right_handed
    //initParameters.coordinate_units = UNIT_MILLIMETER;
    initParameters.coordinate_units = UNIT_METER;

    // Open the camera
    ERROR_CODE err = zed.open(initParameters);
    if (err != SUCCESS) {
        cout << toString(err) << endl;
        zed.close();                
        viewer.exit();
        return 1; // Quit if an error occurred
    }

    // Display help 
    printHelp();

    // Print camera information
    printf("*************************************\n");
    printf("ZED Model                 : %s\n", toString(zed.getCameraInformation().camera_model).c_str());
    printf("ZED Serial Number         : %d\n", zed.getCameraInformation().serial_number);
    printf("ZED Firmware              : %d\n", zed.getCameraInformation().firmware_version);
    printf("ZED Camera Resolution     : %dx%d\n", (int) zed.getResolution().width, (int) zed.getResolution().height);
    printf("ZED Camera FPS            : %d\n", (int) zed.getCameraFPS());
    printf("*************************************\n");

    // Initialize point cloud vie#include "opencv2/imgcodecs.hpp"wer in half-size
    width = (int) floor(zed.getResolution().width/4);
    height = (int) floor(zed.getResolution().height/4);
    viewer.init(width, height);

    // Start the camera thread
    startZED();

    // Set the display callback(cv::Rect(0, 0, width, height)
    glutCloseFunc(close);
    glutMainLoop();
    return 0;
}

/**
    Launch ZED thread. Using a thread here allows to capture a point cloud and update the GL window concurrently.
 **/
void startZED() {
    quit = false;
    zed_callback = std::thread(run);
}

/**
    This function loops to get image and motion data from the ZED. It is similar to a callback.
    Add your own code here.
 **/
void run() {
    // Initialize data for both zed and opencv and share data
    sl::Mat depth_image_zed(width, height, MAT_TYPE_8U_C4);
    cv::Mat depth_image_ocv = slMat2cvMat(depth_image_zed);
    sl::Mat color_image_zed(width, height, MAT_TYPE_8U_C4);
    cv::Mat color_image_ocv = slMat2cvMat(color_image_zed);
    sl::Mat depth_map;
    
    // Initialize buffer for depth value transmission
    int packetSize = 640 * 360;
    uint8_t depthBuffer[packetSize];
    bzero(depthBuffer,packetSize);
    
    while (!quit) {
        // Set runtime parameters
        RuntimeParameters runtimeParameters;
        runtimeParameters.sensing_mode = SENSING_MODE_FILL;

        if (zed.grab(runtimeParameters) == SUCCESS) {
            // Retrieve a colored RGBA point cloud in GPU memory and update GL viewing window
            // width and height specify the total number of columns and rows for the point cloud dataset
            // In this example, we retrieve and display a half size point cloud using width and height parameters
	        //zed.retrieveImage(depth_image_zed, VIEW_DEPTH, MEM_CPU, width, height);
	        zed.retrieveImage(color_image_zed, VIEW_LEFT, MEM_CPU, width, height);
            zed.retrieveMeasure(point_cloud, MEASURE_XYZRGBA, MEM_CPU, width, height);
            //zed.retrieveMeasure(depth_map, MEASURE_DEPTH, MEM_CPU, width, height);

            // Apply background substraction
            pMOG2->apply(color_image_ocv,fgMaskMOG2);
	    
	        // Display depth image
	        //cv::imshow("Depth", depth_image_ocv);
            cv::imshow("FG Mask Mog 2", fgMaskMOG2);
	        cv::imshow("Color", color_image_ocv);

	        cv::waitKey(5);

	        // Display pointcloud
            //viewer.updatePointCloud(point_cloud);

            // Initialize temp values for depth and color
            float depthValue=0;
            float colorValue=0;
            sl::float4 point3D;
            int stride = packetSize / 6;

            // Count the number of moving points
            int count=0;

            // Write depth value into depth buffer
            for (int j=0; j<height; j++) {
                // Access rows of opencv matrix
                const double* fgMaski=fgMaskMOG2.ptr<double>(j);

                for (int i=0; i<width; i++) {

                    // Extract points for moving objects
                    if(/*fgMaski[i]>200 && */count<stride){
                        // initialize buffer index
                        //int index = i + width * j;
                        
                        // Grab depth and point cloud values
                        depth_map.getValue(i,j,&depthValue);
                        //point_cloud.getValue(i,j,&point3D);

                        // Write depth values into buffer
                        /*depthBuffer[index]=(uint8_t)(depthValue*25);
                        if(depthBuffer[index]>255) depthBuffer[index]=0;
                        if(depthBuffer[index]<0) depthBuffer[index]=0;*/

                        // Write point cloud coordinates and color values into buffer
                        point_cloud.getValue(i,j,&point3D);
                        color.a=point3D.w;
                        depthBuffer[count]=(point3D.x+10)*20;
                        if(depthBuffer[count]>255) depthBuffer[count]=255;
                        if(depthBuffer[count]<0) depthBuffer[count]=0;
                        depthBuffer[count+stride]=(point3D.y+10)*20;
                        if(depthBuffer[count+stride]>255) depthBuffer[count+stride]=255;
                        if(depthBuffer[count+stride]<0) depthBuffer[count+stride]=0;
                        depthBuffer[count+2*stride]=point3D.z*20;
                        if(depthBuffer[count+2*stride]>255) depthBuffer[count+2*stride]=255;
                        if(depthBuffer[count+2*stride]<0) depthBuffer[count+2*stride]=0;
                        depthBuffer[count+3*stride]=color.b[0];
                        depthBuffer[count+4*stride]=color.b[1];
                        depthBuffer[count+5*stride]=color.b[2];

                        count++;

                        std::cout<<"\r"<<"# of moving points: "<<point3D.y<<std::flush;
                    }
                }
            }

            // Send depth buffer to server
            int n=send(sockfd,&depthBuffer,packetSize,0);
            if(n<0) {
                cout << endl;
                cout << "Error writing to socket!" << endl;
                zed.close();
                viewer.exit();
            }

            sl::sleep_ms(5);

	        // Print current FPS
	        //cout << "\r" << "Current frame rate: " << ((int)zed.getCurrentFPS()) << std::flush;

            // Print counts
            std::cout<<"\r"<<"# of moving points: "<<count<<std::flush;

        } else sl::sleep_ms(1);
    }
    cout << endl;
}

/**
    This function closes the ZED camera, its callback (thread) and the GL viewer
 **/
void close() {
    quit = true;

    // Stop callback
    zed_callback.join();

    // Exit point cloud viewer
    viewer.exit();

    // Free buffer and close the ZED
    point_cloud.free(MEM_CPU);
    zed.close();
    
    // Close socket
    close(sockfd);
}

/**
* Conversion function between sl::Mat and cv::Mat
**/
cv::Mat slMat2cvMat(Mat& input) {
    // Mapping between MAT_TYPE and CV_TYPE
    int cv_type = -1;
    switch (input.getDataType()) {
	    case MAT_TYPE_32F_C1: cv_type = CV_32FC1; break;
        case MAT_TYPE_32F_C2: cv_type = CV_32FC2; break;
        case MAT_TYPE_32F_C3: cv_type = CV_32FC3; break;
        case MAT_TYPE_32F_C4: cv_type = CV_32FC4; break;
        case MAT_TYPE_8U_C1: cv_type = CV_8UC1; break;
        case MAT_TYPE_8U_C2: cv_type = CV_8UC2; break;
        case MAT_TYPE_8U_C3: cv_type = CV_8UC3; break;
        case MAT_TYPE_8U_C4: cv_type = CV_8UC4; break;
	    default: break;
    }
    // Since cv::Mat data requires a uchar* pointer, we get the uchar1 pointer from sl::Mat (getPtr<T>())
    // cv::Mat and sl::Mat will share a single memory structure
    return cv::Mat(input.getHeight(), input.getWidth(), cv_type, input.getPtr<sl::uchar1>(MEM_CPU));
}

/**
* This function displays help in console
**/
void printHelp() {
    cout << endl;
    cout << "*************************************" << endl;
    cout << "**  Press 'q' to quit application  **" << endl;
    cout << "*************************************" << endl;
    cout << endl;
}

/**
 * This function displays error in case of network faliure
 **/
void error(const char *msg) {
    perror(msg);
    exit(0);
}